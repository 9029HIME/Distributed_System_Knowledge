# 55-Redis单机存储问题

1. 数据丢失问题

   Redis作为直接操作内存的缓存工具，不幸宕机的话数据有可能会丢失，**需要依靠持久化机制来避免**。

2. 并发能力问题

   Redis虽然基于1个主线程+IO多路复用的机制来完成缓存数据的读写，但海量请求过来单机Redis还是撑不住的，**需要依靠主从集群来缓解**。

3. 故障恢复问题

   Redis集群其中一个节点宕机后，需要有完善的机制来维持高可用性，**通过哨兵机制来实现**。

4. 存储能力问题

   为了提高存储能力，可以采用**类似Es、Kafka那样的数据分片+备份的形式，分散到每个节点上**。

# Redis持久化

Redis有2种持久化方案：RDB、AOF。

## 56-RDB

即Redis Database Backup File。RDB方式的过程是Redis主进程开启1个进程，然后子进程将Redis运行时内存存储的数据**写入一个持久化文件**里，当Redis重启后，从磁盘读取这个持久化文件，达到恢复数据的效果。这个持久化文件可以理解为一个快照，也叫RDB文件。

对于RDB文件的生成，其实有2种方式：

1. 通过redis-cli，运行save命令

   但是这种做法实际上是让Redis主进程来写RDB文件，要记得操作磁盘肯定比操作内存慢得多，如果数据量大的话会导致主进程没有时间去响应Redis的读写请求，从而导致阻塞超时，所以一般不用这种方式。

2. 通过redis-cli，运行bgsave命令

   通过这个命令，可以让Redis主进程派生一个子进程，子进程来完成RDB的写入，不会影响主进程的读写操作。

3. 关闭redis时，会进行一次RDB的写入（除了kill -9）

4. redis默认有一套规则来**运行时触发RDB（派生子进程 ）**，在redis.conf配置文件里：

   ```
   save 900 1
   save 300 10
   save 60 10000
   ```

   这里的意思分别是：在900秒内发生1个key的操作，就进行RDB写入，在300秒内发生10个key的操作，就进行RDB写入，在60秒内发生10000个key的操作，就进行RDB写入。这些条件都是**或的关系**，任意一个触发都会进行RBD写入。

## 57-RDB的一些细节

通过配置文件可以设置RDB的其他细节：

```
rdbcompression yes #是否在写入rdb文件时进行压缩
dbfilename dump.rdb	#rdb文件名
dir ./	#rdb所在路径
```

redis的启动也是通过配置文件的路径+文件名找到RDB文件进行读取，不过这个压缩存储虽然减轻了磁盘存储压力，但是也增加了CPU的消耗，对于磁盘空间充足的情况下，没必要开启。

![image](https://user-images.githubusercontent.com/48977889/171335281-711d54c3-f4fa-48a6-b320-5b1ac8d27a51.png)

对于子进程来说，共享了主进程的页表，从而操作与主进程一样的虚拟空间（联动[01 内存管理.md](https://github.com/9029HIME/OS/blob/master/src/04 内存/01 内存管理.md)），子进程主要的作用是读取数据写入RDB文件。在子进程读取期间，读取数据所在的内存区域需要变成只读。当有新的请求过来操作数据时，要将该数据在内存中完整拷贝一份副本，之后主线程的所有操作都针对这个副本来进行。**当然，在RDB写入操作完成后，子进程会被shutdown，并且之前被派生的只读数据也会被释放空间（我猜的）**。

在一个极端情况下，子进程执行RDB操作比较慢的时候，发生了对所有数据的写请求...这时候会导致Redis的内存占用直接飙升，因为很多数据都要进行拷贝来满足主线程的操作。当然这只是一种极端情况，这个说法只是提醒我们要对Redis的操作内存作出冗余。

## 58-RDB的数据丢失问题

结合知识点56来看，虽然说Redis正常shutdown会触发RDB，运行时也会根据操作规则进行动态的RDB。但Redis在运行时以外宕机或者被kill -9后，在RDB空档期产生的数据可以说是完全丢失了，因为它们根本没被写入RDB文件。等Redis重启读取RDB文件后也不会读到它们。

## 59-AOF

即Append Only File，AOF和RDB有点类似，也是将数据写入一个文件，**也是可以通过主进程或子进程来完成**，RDB存储的是key和value，而AOF存储的是Redis的**写、改、删操作记录**，当Redis启动时会读取AOF的操作记录，根据操作记录的顺序生成值，注意是生成！！！RDB的话更像是直接导入值，这也是为什么AOF的恢复会比RDB要慢一些。 

AOF默认是关闭的，需要修改配置文件来开启：

```
appendonlyfile yes #开启aof
appendfilename "appendonly.aof" #aof文件
```

对于AOF的触发，也是有一套规则：

```
appendfsync 策略值
```

策略值包含awalys、everysec、no。

1. awalys代表每次进行一个写操作，**主进程**会立即将操作记录写入aof文件里，注意写入aof文件是一个磁盘操作了。虽然与RDB相比它是针对1条数据，但这样做就有点类似MySQL的写操作了，每次数据的写都要主进程去写磁盘，自然效率是没那么高的，也会影响到接下来的请求效率。
1. everysec代表主进程会将操作写入AOF缓冲区，**主进程**每隔1秒钟子进程将AOF缓冲区的数据写入aof文件里。在1秒钟的空档期内Redis宕机的话会导致空档期的产生的数据丢失，可靠性稍微弱一些。
1. no代表主进程会将操作写入AOF缓冲区，并且由OS负责将缓冲区的数据写入aof文件里，有点像kafka的消息刷盘机制。当然OS什么时候写入呢？这个我们无从得知，只能让OS自己控制。

因为AOF记录的是操作记录，那么在一定时间内，操作记录的数量和内容会变得冗余，比如在一段时间内操作了set num 1、set num 2、set num 3，然后对num这个key就不再操作了。那么对于aof文件来说前两个操作记录是没意义的。对于这种情况redis提供了AOF的重写机制，用来重新整理、润色、优化aof文件的内容。通过执行bgrewriteaof命令或者**阈值触发**，主进程就会派生1个子进程来完成aof文件的重写。这里的阈值有2个，可以通过配置文件更改：

1. auto-aof-rewrite-percentage 60

   当**aof文件大小**比**上次重写后的大小**多出60%，触发重写。

2. auto-aof-rewrite-min-size 64mb

   当**aof文件大小**在64mb大小以上，才会触发重写

这2个规则是**和**的关系，必须满足两个才会触发文件重写。当然，子进程重写过程中肯定会**面临主进程处理请求的情况**，这种时候产生的新值还是要同步到aof文件里的，但具体怎么做呢？主进程会将这些新值的aof记录写入**AOF重写缓冲区**，当子进程重写AOF完成后，主进程会调用一个**信号处理函数**，这时主进程会将AOF重写缓冲区的数据追加到重写完成后的AOF文件里。**在执行信号处理函数的主进程是不会处理客户端请求的**。

# Redis主从集群

先给我的Ubuntu01和Ubuntu02安装好redis